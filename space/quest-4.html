<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Signal Processing - Repo Adventure</title>
    <link rel="stylesheet" href="assets/theme.css">
    <link rel="stylesheet" href="../assets/shared/quest-navigator.css">
    <link rel="stylesheet" href="../assets/theme-toggle.css">
    
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "tk53e05gf2");
    </script>
    
    <!-- Prism.js for syntax highlighting -->
    <!-- Using minimal theme since we override all styles with our custom theme -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
        // Configure Prism autoloader for syntax highlighting
        if (window.Prism && window.Prism.plugins && window.Prism.plugins.autoloader) {
            window.Prism.plugins.autoloader.languages_path = 'https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/';
        }

        // Trigger Prism highlighting after page load
        document.addEventListener('DOMContentLoaded', function() {
            if (window.Prism) {
                window.Prism.highlightAll();
            }
        });
    </script>
</head>
<body class="theme-space">

    <nav class="navbar">
        <div class="nav-content">
            <div class="nav-left">
                <a href="https://github.com/danwahlin/RealtimeAIApp-JS" target="_blank" rel="noopener noreferrer" class="github-link">
                    <img src="../assets/shared/github-mark-white.svg" alt="GitHub" width="24" height="24">
                </a>
                <a href="index.html">The Galactic AI Navigator</a>
            </div>
            <div class="nav-middle">
            </div>
            <div class="nav-right">
                <a href="../index.html" class="nav-link">Change Adventure</a>
                <a href="#" class="nav-link quest-map-trigger">Quests</a>
                <button class="theme-toggle-btn" aria-label="Switch to light mode" type="button">
                    <div class="theme-toggle-slider">
                        <svg class="toggle-icon sun-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="4" fill="currentColor"/>
                            <path d="M12 2v2M12 20v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M2 12h2M20 12h2M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42" stroke="currentColor" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                        <svg class="toggle-icon moon-icon" viewBox="0 0 24 24">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                        </svg>
                    </div>
                </button>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="quest-content">
    <h1>Quest 4: Audio Signal Processing Pipeline</h1>
<hr>
<p>In the heart of the <em>Galactic Navigator</em>, the Audio Processing Core hums with life, converting stellar audio streams into actionable intelligence. Here, the Recorder and Player Modules work in tandem to capture cosmic whispers and playback decoded messages. Your mission is to ensure these modules operate seamlessly, enabling the crew to communicate with distant civilizations. The Recorder captures interstellar signals, converting them into a usable format, while the Player translates AI responses into audible transmissions for the crew.</p>
<h2>Key Takeaways</h2>
<p>After completing this quest, you will understand:</p>
<ul>
<li>üéØ <strong>Audio Worklet Basics</strong>: How custom AudioWorklet processors handle real-time audio streaming in the browser.</li>
<li>üîç <strong>PCM16 Audio Format</strong>: The importance of converting audio data for compatibility with Web Audio APIs.</li>
<li>‚ö° <strong>AudioContext Lifecycle</strong>: Techniques to manage and reuse <code class="inline-code">AudioContext</code> for efficient audio processing.</li>
<li>üí° <strong>Error Handling in Audio Pipelines</strong>: How to ensure robust audio processing with fallback mechanisms.</li>
</ul>
<h2>File Exploration</h2>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/player.service.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">client/src/app/core/player.service.ts</code></a></h3>
<p>The Player Module is responsible for converting AI-generated responses into audio signals that can be played back to the crew. It uses an <code class="inline-code">AudioWorklet</code> to process PCM16 audio data in real-time and connects the processed output to the browser&#39;s audio destination. This module ensures smooth playback even under varying conditions, such as buffer underruns or invalid inputs.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/player.service.ts#L11" target="_blank" rel="noopener noreferrer"><code class="inline-code">init</code></a>: Initializes the <code class="inline-code">AudioContext</code> and sets up the <code class="inline-code">PlaybackProcessor</code> for audio playback.</li>
<li><a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/player.service.ts#L62" target="_blank" rel="noopener noreferrer"><code class="inline-code">play</code></a>: Sends PCM16 audio buffers to the <code class="inline-code">PlaybackProcessor</code> for real-time playback.</li>
<li><a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/player.service.ts#L85" target="_blank" rel="noopener noreferrer"><code class="inline-code">clear</code></a>: Clears the playback buffer to reset the audio state.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async init(sampleRate: number) {
  if (this.playbackNode === null) {
    this.audioContext = new AudioContext({ sampleRate });
    const playbackWorkletBlobUrl = URL.createObjectURL(new Blob([`
      registerProcessor(&#39;playback-worklet&#39;, class PlaybackProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.port.onmessage = this.handleMessage.bind(this);
          this.buffer = [];
        }

        handleMessage(event) {
          if (event.data === null) {
            this.buffer = [];
            return;
          }
          this.buffer.push(...event.data);
        }

        process(inputs, outputs, parameters) {
          const output = outputs[0];
          const channel = output[0];

          if (this.buffer.length &gt; channel.length) {
            const toProcess = this.buffer.splice(0, channel.length);
            channel.set(toProcess.map((v) =&gt; v / 32768));
          } else {
            channel.set(this.buffer.map((v) =&gt; v / 32768));
            this.buffer = [];
          }

          return true;
        }
      });
    `], { type: &#39;application/javascript&#39; }));
    await this.audioContext.audioWorklet.addModule(playbackWorkletBlobUrl);
    setTimeout(() =&gt; {
      if (this.audioContext &amp;&amp; !this.initialized) {
        this.playbackNode = new AudioWorkletNode(this.audioContext, &#39;playback-worklet&#39;);
        this.playbackNode.connect(this.audioContext.destination);
        this.initialized = true;
      }
    }, 100);
  }
}
</code></pre>
<ul>
<li>This function sets up the <code class="inline-code">AudioContext</code> and registers a custom <code class="inline-code">AudioWorkletProcessor</code> for playback.</li>
<li>The <code class="inline-code">PlaybackProcessor</code> converts PCM16 data into float values for Web Audio compatibility.</li>
<li>The use of a <code class="inline-code">Blob</code> allows the processor code to be embedded directly in the service, simplifying deployment.</li>
<li>The <code class="inline-code">setTimeout</code> ensures the <code class="inline-code">AudioContext</code> is fully initialized before connecting nodes.</li>
</ul>
<hr>
<pre><code class="language-typescript">async play(buffer: Int16Array) {
  if (!this.playbackNode || !this.audioContext) {
    console.warn(&#39;Audio not initialized&#39;);
    return;
  }

  if (this.audioContext.state === &#39;suspended&#39;) {
    await this.audioContext.resume();
  }

  if (buffer &amp;&amp; buffer.length &gt; 0) {
    try {
      this.playbackNode.port.postMessage(buffer);
    } catch (error) {
      console.error(&#39;Failed to play audio:&#39;, error);
    }
  } else {
    console.warn(&#39;Empty or invalid audio buffer received so unable to play the audio&#39;);
  }
}
</code></pre>
<ul>
<li>Sends PCM16 audio data to the <code class="inline-code">PlaybackProcessor</code> for playback.</li>
<li>Resumes the <code class="inline-code">AudioContext</code> if it is in a suspended state, ensuring audio can play.</li>
<li>Handles errors gracefully, logging issues without crashing the application.</li>
</ul>
<hr>
<h3><span class="header-prefix">File:</span> <a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/recorder.service.ts" target="_blank" rel="noopener noreferrer"><code class="inline-code">client/src/app/core/recorder.service.ts</code></a></h3>
<p>The Recorder Module captures audio signals from the crew or external sources, converting them into PCM16 format for transmission to the AI system. It uses an <code class="inline-code">AudioWorklet</code> to process audio streams in real-time, ensuring compatibility with the WebSocket-based communication pipeline.</p>
<h4>Highlights</h4>
<ul>
<li><a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/recorder.service.ts#L26" target="_blank" rel="noopener noreferrer"><code class="inline-code">start</code></a>: Initializes the <code class="inline-code">AudioContext</code> and sets up the <code class="inline-code">RecorderPCMProcessor</code> for audio capture.</li>
<li><code class="inline-code">RecorderPCMProcessor</code>: Converts <code class="inline-code">Float32</code> audio data into <code class="inline-code">Int16</code> format for efficient transmission.</li>
<li><a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/recorder.service.ts#L116" target="_blank" rel="noopener noreferrer"><code class="inline-code">stop</code></a>: Stops the recording process and cleans up resources.</li>
</ul>
<h4>Code</h4>
<pre><code class="language-typescript">async start(stream: MediaStream) {
  if (this.isRecording) {
    console.warn(&#39;Recording already in progress. Ignoring new start call.&#39;);
    return;
  }
  this.isRecording = true;
  try {
    this.mediaStream = stream;
    if (!this.audioContext || this.audioContext.state === &#39;closed&#39;) {
      this.audioContext = new AudioContext({
        latencyHint: &#39;interactive&#39;,
        sampleRate: 24000,
      });
    }

    this.mediaStreamSource = this.audioContext.createMediaStreamSource(this.mediaStream);

    if (!this.workletBlobUrl) {
      this.workletBlobUrl = URL.createObjectURL(new Blob([`
        registerProcessor(&#39;recorder-worklet&#39;, class RecorderPCMProcessor extends AudioWorkletProcessor {
          process(inputs) {
            const input = inputs[0];
            if (input.length &gt; 0) {
              const float32Buffer = input[0];
              const int16Buffer = this.convertFloat32ToInt16(float32Buffer);
              this.port.postMessage(int16Buffer);
            }
            return true;
          }

          convertFloat32ToInt16(float32Array) {
            const int16Array = new Int16Array(float32Array.length);
            for (let i = 0; i &lt; float32Array.length; i++) {
              let val = Math.floor(float32Array[i] * 0x7fff);
              val = Math.max(-0x8000, Math.min(0x7fff, val));
              int16Array[i] = val;
            }
            return int16Array;
          }
        });
      `], { type: &#39;application/javascript&#39; }));
    }

    if (!this.workletNode) {
      await this.audioContext.audioWorklet.addModule(this.workletBlobUrl);
    }

    this.workletNode = new AudioWorkletNode(this.audioContext, &#39;recorder-worklet&#39;, {
      numberOfInputs: 1,
      numberOfOutputs: 1,
      channelCount: 1,
    });

    this.workletNode.port.onmessage = (event) =&gt; {
      if (this.onDataAvailable) {
        this.onDataAvailable(event.data);
      }
    };

    this.mediaStreamSource.connect(this.workletNode);
    this.workletNode.connect(this.audioContext.destination);
  } catch (error) {
    console.error(&#39;Error starting recorder:&#39;, error);
    this.stop();
  }
}
</code></pre>
<ul>
<li>Captures audio from a <code class="inline-code">MediaStream</code> and processes it using a custom <code class="inline-code">AudioWorkletProcessor</code>.</li>
<li>Converts <code class="inline-code">Float32</code> audio data into <code class="inline-code">Int16</code> format for compatibility with downstream systems.</li>
<li>The <code class="inline-code">onDataAvailable</code> callback allows the processed audio to be sent to the WebSocket server.</li>
</ul>
<hr>
<pre><code class="language-typescript">async stop() {
  console.log(&quot;Recorder Stop called&quot;);
  this.isRecording = false;

  if (this.mediaStream) {
    this.mediaStream.getTracks().forEach((track) =&gt; track.stop());
    this.mediaStream = null;
  }
  if (this.workletNode) {
    this.workletNode.port.close();
    this.workletNode.disconnect();
    this.workletNode = null;
  }
  if (this.mediaStreamSource) {
    this.mediaStreamSource.disconnect();
    this.mediaStreamSource = null;
  }
}
</code></pre>
<ul>
<li>Stops the recording process and cleans up resources, ensuring no memory leaks.</li>
<li>Disconnects the <code class="inline-code">AudioWorkletNode</code> and <code class="inline-code">MediaStreamAudioSourceNode</code> to release system resources.</li>
</ul>
<hr>
<h2>Helpful Hints</h2>
<ul>
<li>Use the <a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/player.service.ts#L11" target="_blank" rel="noopener noreferrer"><code class="inline-code">init</code></a> method in <code class="inline-code">PlayerService</code> to ensure the playback system is ready before sending audio buffers.</li>
<li>Experiment with different <code class="inline-code">sampleRate</code> values in <code class="inline-code">RecorderService</code> to understand their impact on audio quality.</li>
<li>Review how <a href="https://github.com/danwahlin/RealtimeAIApp-JS/blob/main/client/src/app/core/recorder.service.ts#L67" target="_blank" rel="noopener noreferrer"><code class="inline-code">convertFloat32ToInt16</code></a> ensures compatibility with systems expecting PCM16 audio data.</li>
</ul>
<h2>Try This</h2>
<p>Challenge yourself to deepen your understanding:</p>
<ol>
<li><p><strong>Modify Audio Buffer Size</strong>: Adjust the buffer size in <code class="inline-code">PlaybackProcessor</code> to observe its impact on playback smoothness. Smaller buffers reduce latency but may cause underruns.</p>
</li>
<li><p><strong>Implement Pause/Resume</strong>: Extend the <code class="inline-code">RecorderService</code> and <code class="inline-code">PlayerService</code> to support pausing and resuming audio streams. This will help you understand state management in audio pipelines.</p>
</li>
<li><p><strong>Add Audio Filters</strong>: Enhance the <code class="inline-code">PlaybackProcessor</code> with a simple low-pass filter to modify the audio output. Experiment with different filter parameters to observe their effects.</p>
</li>
</ol>
<hr>
<p>Excellent work! Continue to the next quest to uncover more mysteries of the starship&#39;s systems.</p>
<p>Mission Control confirms a stellar achievement in Audio Signal Processing‚Äîyour cosmic journey is 60% complete, keep your engines roaring toward the stars! üöÄ‚≠êüì°</p>

</div>


      <div class="quest-navigation quest-navigation-bottom">
        <a href="quest-3.html" class="prev-quest-btn">‚Üê Previous: Quest 3</a>
        <a href="quest-5.html" class="next-quest-btn">Next: Quest 5 ‚Üí</a>
      </div>
    
    </div>
    
    <footer class="footer">
        <div class="footer-content">
            <span>Created using <a href="https://github.com/DanWahlin/ai-repo-adventures" target="_blank" rel="noopener noreferrer" class="repo-link">AI Repo Adventures</a></span>
        </div>
    </footer>
    
    <!-- Quest Navigator Script (for navbar Quests button functionality) -->
    <script src="../assets/shared/quest-navigator.js"></script>
    <!-- Theme Toggle Script (for light/dark mode toggle) -->
    <script src="../assets/theme-toggle.js"></script>
</body>
</html>